{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58d8bd1f-fa29-4d4b-a320-c76538f2302f",
   "metadata": {},
   "source": [
    "# Feastless Feature Store Setup \n",
    "\n",
    "We saw performance improvements from removing the usage of the feast SDK in this pipeline. Because the features from feast are stored in protobuf, the feature store setup to run the ``03-remove-feast-sdk`` model is different from that of the original setup located in this files parent folder. \n",
    "\n",
    "This notebook will walk you through setting up Redis as a feature store without feast.\n",
    "\n",
    "## Steps\n",
    "1) [**Feature Store Setup**](#Feature-Store-Setup)\n",
    "2) [**Redis ANN Index Setup**](#Redis-ANN-Index-Setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7f3bd",
   "metadata": {},
   "source": [
    "### Import required libraries and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1586d8-e5a6-40c3-b6bb-61a3e62fa34c",
   "metadata": {},
   "source": [
    "*These notebooks are developed and tested using `merlin-tensorflow:22.11` container on [NVIDIA's docker registry](https://catalog.ngc.nvidia.com/containers?filters=&orderBy=dateModifiedDESC&query=merlin).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08cdbfcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 22:03:48.725134: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-08 22:03:52.259741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 22:03:52.260940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 22:03:52.261704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 22:03:52.492599: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-08 22:03:52.493055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 22:03:52.493965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 22:03:52.494717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 22:03:53.037752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 22:03:53.038799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 22:03:53.039663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 22:03:53.040415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13107 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import merlin.models.tf as mm\n",
    "import nvtabular as nvt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from merlin.datasets.ecommerce import transform_aliccp\n",
    "from merlin.schema.tags import Tags\n",
    "from merlin.io.dataset import Dataset\n",
    "from nvtabular.ops import *\n",
    "\n",
    "# for running this example on CPU, comment out the line below\n",
    "# os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baad8ae3",
   "metadata": {},
   "source": [
    "First, we define our input path and feature repo path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ddb370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output path for data\n",
    "DATA_DIR = \"/model-data/aliccp\"\n",
    "BASE_DIR = \"/workdir\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a3f3f-81d8-489c-835f-c62f76df22d5",
   "metadata": {},
   "source": [
    "Next, we need to load the previously trained assets. If you have your own great, make sure they end up in the same folder structure as the ones we will pull from the publically hosted S3 bucket below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da1f434-f5a1-4478-b588-7e7ec17e6a88",
   "metadata": {},
   "source": [
    "## Feature Store Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a4e939-d3cf-44f0-9012-d2af3264ee25",
   "metadata": {},
   "source": [
    "We need to create a Feast feature repository. [Feast](https://feast.dev/) is an end-to-end open source feature store for machine learning. Feast (Feature Store) is a customizable operational data system that re-uses existing infrastructure to manage and serve machine learning features to real-time models.\n",
    "\n",
    "Our feature repo will live at the defined path below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78315676-eb6c-405a-b1fd-3174ea328406",
   "metadata": {},
   "source": [
    "### Prepare User and Item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0b369c-2f01-42e3-9f3c-74c3ff4a6d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_shops</th>\n",
       "      <th>user_profile</th>\n",
       "      <th>user_group</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_age</th>\n",
       "      <th>user_consumption_2</th>\n",
       "      <th>user_is_occupied</th>\n",
       "      <th>user_geography</th>\n",
       "      <th>user_intentions</th>\n",
       "      <th>user_brands</th>\n",
       "      <th>user_categories</th>\n",
       "      <th>user_id_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  user_shops  user_profile  user_group  user_gender  user_age  \\\n",
       "0        1           1             1           1            1         1   \n",
       "1        2           2             1           1            1         1   \n",
       "2        3           3             1           1            1         1   \n",
       "3        4           4             1           1            1         1   \n",
       "4        5           5             1           1            1         1   \n",
       "\n",
       "   user_consumption_2  user_is_occupied  user_geography  user_intentions  \\\n",
       "0                   1                 1               1                1   \n",
       "1                   1                 1               1                2   \n",
       "2                   1                 1               1                3   \n",
       "3                   1                 1               1                4   \n",
       "4                   1                 1               1                5   \n",
       "\n",
       "   user_brands  user_categories  user_id_raw  \n",
       "0            1                1            7  \n",
       "1            2                2            8  \n",
       "2            3                3            6  \n",
       "3            4                4            9  \n",
       "4            5                5            5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from merlin.models.utils.dataset import unique_rows_by_features\n",
    "\n",
    "# Load pre-generated User features file\n",
    "user_features = Dataset(os.path.join(DATA_DIR, \"user_features.parquet\")).to_ddf().compute()\n",
    "user_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a46bd8c-1337-4c74-a85b-25348a897d90",
   "metadata": {},
   "source": [
    "We will artificially add `datetime` and `created` timestamp columns to our user_features dataframe. This required by Feast to track the user-item features and their creation time and to determine which version to use when we query Feast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b24e6898-7e7e-48c9-80a1-8b95a62917e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_category</th>\n",
       "      <th>item_shop</th>\n",
       "      <th>item_brand</th>\n",
       "      <th>item_id_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  item_category  item_shop  item_brand  item_id_raw\n",
       "0        1              1          1           1            7\n",
       "1        2              2          2           2            6\n",
       "2        3              3          3           3            8\n",
       "3        4              4          4           4            9\n",
       "4        5              5          5           5            5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-generated Item features file\n",
    "item_features = Dataset(os.path.join(DATA_DIR, \"item_features.parquet\")).to_ddf().compute()\n",
    "item_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa489e34-a380-46b8-a73a-0e85dcd26b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write parquet file to feature_repo\n",
    "user_features.to_parquet(\n",
    "    os.path.join(BASE_DIR, \"/feature_repo/data\", \"user_features.parquet\")\n",
    ")\n",
    "item_features.to_parquet(\n",
    "    os.path.join(BASE_DIR, \"feature_repo/data\", \"item_features.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe30dc97-1f0d-4f9c-a13f-ff382ef084ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from redis import client\n",
    "\n",
    "host, port = os.environ.get(\"FEATURE_STORE_ADDRESS\", \"localhost:6379\")\n",
    "redis_client = client.Redis(host=host, port=port, decode_responses=True)\n",
    "\n",
    "data_path = os.path.join(BASE_DIR, \"feature_repo/data\")\n",
    "\n",
    "def prepare_feature_store(data_path):\n",
    "    user_dataset = pd.read_parquet(f\"{data_path}/user_features.parquet\")\n",
    "    item_dataset = pd.read_parquet(f\"{data_path}/item_features.parquet\")\n",
    "\n",
    "    load_dataframe(\"user\", \"user_id_raw\", user_dataset)\n",
    "    load_dataframe(\"item\", \"item_id_raw\", item_dataset)\n",
    "    \n",
    "def load_dataframe(feature_name, key_name, df):\n",
    "    records = df.to_dict(orient=\"records\")\n",
    "    pipe = redis_client.pipeline()\n",
    "    for record in records:\n",
    "        key = \":\".join((feature_name, str(record[key_name])))\n",
    "        pipe.hset(key, mapping=record)\n",
    "    pipe.execute()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f78348e4-4861-49c0-b8fb-0072dfdd6f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.9 ms, sys: 9.48 ms, total: 51.4 ms\n",
      "Wall time: 64.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this should take about 2 minutes\n",
    "prepare_feature_store(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "657f2726-b9ea-45d2-8877-d67777d199cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count  Dtype\n",
      "---  ------              --------------  -----\n",
      " 0   user_id             2 non-null      int64\n",
      " 1   user_shops          2 non-null      int64\n",
      " 2   user_profile        2 non-null      int64\n",
      " 3   user_group          2 non-null      int64\n",
      " 4   user_gender         2 non-null      int64\n",
      " 5   user_age            2 non-null      int64\n",
      " 6   user_consumption_2  2 non-null      int64\n",
      " 7   user_is_occupied    2 non-null      int64\n",
      " 8   user_geography      2 non-null      int64\n",
      " 9   user_intentions     2 non-null      int64\n",
      " 10  user_brands         2 non-null      int64\n",
      " 11  user_categories     2 non-null      int64\n",
      " 12  user_id_raw         2 non-null      int64\n",
      "dtypes: int64(13)\n",
      "memory usage: 336.0 bytes\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame([redis_client.hgetall(\"user:8\"), redis_client.hgetall(\"user:9\")]).astype(int).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff9f2f04-60b8-4b05-8af3-a18c7d4e367f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323 µs ± 9.07 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "redis_client.hgetall(\"user:8\")\n",
    "# Fast feature retrieval from Redis, NOTEABLY faster than feast SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff205220-d50f-476f-8b07-f43a4082c886",
   "metadata": {},
   "source": [
    "### Explore Feature Repo Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec175c8d-7d92-4323-bdd9-fbf7a1941b08",
   "metadata": {},
   "source": [
    "## Redis ANN Index Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff30ceab-b264-4509-9c5b-5a10425e143b",
   "metadata": {},
   "source": [
    "### Load Item Embeddings\n",
    "We will load the pre-generated Item embeddings from file in preparation for loading into the Redis Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00f1fe65-882e-4962-bb16-19a130fda215",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.034885</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>0.018455</td>\n",
       "      <td>0.037430</td>\n",
       "      <td>0.026332</td>\n",
       "      <td>0.012729</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.069112</td>\n",
       "      <td>0.044133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027153</td>\n",
       "      <td>-0.029950</td>\n",
       "      <td>-0.020070</td>\n",
       "      <td>-0.067773</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>-0.001353</td>\n",
       "      <td>-0.055582</td>\n",
       "      <td>0.042481</td>\n",
       "      <td>0.013875</td>\n",
       "      <td>0.021228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.021357</td>\n",
       "      <td>-0.026375</td>\n",
       "      <td>0.069090</td>\n",
       "      <td>-0.011445</td>\n",
       "      <td>0.025277</td>\n",
       "      <td>-0.010337</td>\n",
       "      <td>0.008437</td>\n",
       "      <td>0.042574</td>\n",
       "      <td>0.060663</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037270</td>\n",
       "      <td>-0.039209</td>\n",
       "      <td>0.013558</td>\n",
       "      <td>-0.006484</td>\n",
       "      <td>-0.029601</td>\n",
       "      <td>0.073999</td>\n",
       "      <td>0.009857</td>\n",
       "      <td>-0.022534</td>\n",
       "      <td>-0.009440</td>\n",
       "      <td>-0.025069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.018197</td>\n",
       "      <td>0.017502</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.008534</td>\n",
       "      <td>0.015912</td>\n",
       "      <td>0.006360</td>\n",
       "      <td>-0.001660</td>\n",
       "      <td>0.007613</td>\n",
       "      <td>0.054932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045789</td>\n",
       "      <td>0.033707</td>\n",
       "      <td>-0.025606</td>\n",
       "      <td>-0.020231</td>\n",
       "      <td>0.068983</td>\n",
       "      <td>0.030158</td>\n",
       "      <td>-0.054312</td>\n",
       "      <td>-0.006741</td>\n",
       "      <td>0.026637</td>\n",
       "      <td>-0.040934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.018756</td>\n",
       "      <td>-0.057435</td>\n",
       "      <td>0.027142</td>\n",
       "      <td>0.069214</td>\n",
       "      <td>-0.014137</td>\n",
       "      <td>0.063484</td>\n",
       "      <td>0.049648</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>0.041440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050948</td>\n",
       "      <td>-0.007804</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>-0.059237</td>\n",
       "      <td>-0.018273</td>\n",
       "      <td>-0.005572</td>\n",
       "      <td>-0.017192</td>\n",
       "      <td>0.033178</td>\n",
       "      <td>0.050670</td>\n",
       "      <td>0.040354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.044985</td>\n",
       "      <td>0.015847</td>\n",
       "      <td>-0.041081</td>\n",
       "      <td>-0.006620</td>\n",
       "      <td>-0.003196</td>\n",
       "      <td>-0.045210</td>\n",
       "      <td>-0.031615</td>\n",
       "      <td>-0.093638</td>\n",
       "      <td>0.007464</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014779</td>\n",
       "      <td>0.057923</td>\n",
       "      <td>-0.015743</td>\n",
       "      <td>-0.048929</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>-0.043618</td>\n",
       "      <td>-0.137103</td>\n",
       "      <td>-0.019580</td>\n",
       "      <td>0.025585</td>\n",
       "      <td>0.028937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id         0         1         2         3         4         5  \\\n",
       "0        1 -0.034885 -0.000131  0.018455  0.037430  0.026332  0.012729   \n",
       "1        2  0.021357 -0.026375  0.069090 -0.011445  0.025277 -0.010337   \n",
       "2        3 -0.018197  0.017502  0.002263  0.008534  0.015912  0.006360   \n",
       "3        4 -0.018756 -0.057435  0.027142  0.069214 -0.014137  0.063484   \n",
       "4        5  0.044985  0.015847 -0.041081 -0.006620 -0.003196 -0.045210   \n",
       "\n",
       "          6         7         8  ...        54        55        56        57  \\\n",
       "0  0.006760  0.069112  0.044133  ... -0.027153 -0.029950 -0.020070 -0.067773   \n",
       "1  0.008437  0.042574  0.060663  ... -0.037270 -0.039209  0.013558 -0.006484   \n",
       "2 -0.001660  0.007613  0.054932  ... -0.045789  0.033707 -0.025606 -0.020231   \n",
       "3  0.049648 -0.000459  0.041440  ... -0.050948 -0.007804  0.001069 -0.059237   \n",
       "4 -0.031615 -0.093638  0.007464  ... -0.014779  0.057923 -0.015743 -0.048929   \n",
       "\n",
       "         58        59        60        61        62        63  \n",
       "0  0.002420 -0.001353 -0.055582  0.042481  0.013875  0.021228  \n",
       "1 -0.029601  0.073999  0.009857 -0.022534 -0.009440 -0.025069  \n",
       "2  0.068983  0.030158 -0.054312 -0.006741  0.026637 -0.040934  \n",
       "3 -0.018273 -0.005572 -0.017192  0.033178  0.050670  0.040354  \n",
       "4  0.000438 -0.043618 -0.137103 -0.019580  0.025585  0.028937  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_embeddings = Dataset(os.path.join(DATA_DIR, \"item_embeddings.parquet\")).to_ddf().compute()\n",
    "item_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a58db7-fa15-49a6-a47c-d43a66f86654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import redis.asyncio as redis\n",
    "from redis.commands.search.query import Query\n",
    "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
    "from redis.commands.search.field import VectorField\n",
    "\n",
    "# Connect to the Redis client\n",
    "redis_conn = redis.Redis(host=host, port=port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf71e416-face-4adf-9b5f-579308f495cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'OK'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Redis ANN Index Params and Fields\n",
    "INDEX_NAME = \"candidate_index\"\n",
    "VECTOR_FIELD_NAME = \"item_embedding\"\n",
    "\n",
    "vector_field = VectorField(\n",
    "    VECTOR_FIELD_NAME,\n",
    "    \"HNSW\", {\n",
    "        \"TYPE\": \"FLOAT32\",\n",
    "        \"DIM\": 64,\n",
    "        \"DISTANCE_METRIC\": \"IP\",\n",
    "        \"INITIAL_CAP\": len(item_embeddings),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create ANN Index\n",
    "await redis_conn.ft(INDEX_NAME).create_index(\n",
    "    fields = [vector_field],\n",
    "    definition= IndexDefinition(prefix=[\"ITEM:\"], index_type=IndexType.HASH)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58199275-78f5-45de-8819-3a081da8d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write item embeddings to Redis\n",
    "async def write_item_embeddings(embs, n: int, redis_conn: redis.Redis):\n",
    "    semaphore = asyncio.Semaphore(n)\n",
    "    async def write(row):\n",
    "        async with semaphore:\n",
    "            item_id = int(row.pop(\"item_id\"))\n",
    "            entry = {\n",
    "                \"item_id\": item_id,\n",
    "                VECTOR_FIELD_NAME: np.array(row.values, dtype=np.float32).tobytes()\n",
    "            }\n",
    "            await redis_conn.hset(f\"ITEM:{item_id}\", mapping=entry)\n",
    "    asyncio.gather(*[write(row[1]) for row in embs.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40bdf656-65af-492a-a88f-7aae46581812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write embeddings to Redis ANN Index created above\n",
    "await write_item_embeddings(item_embeddings, 100, redis_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c74d0ed5-4f11-4312-b5a5-13e74d5cd365",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index_name': 'candidate_index',\n",
       " 'index_definition': [b'key_type',\n",
       "  b'HASH',\n",
       "  b'prefixes',\n",
       "  [b'ITEM:'],\n",
       "  b'default_score',\n",
       "  b'1'],\n",
       " 'attributes': [[b'identifier',\n",
       "   b'item_embedding',\n",
       "   b'attribute',\n",
       "   b'item_embedding',\n",
       "   b'type',\n",
       "   b'VECTOR']],\n",
       " 'index_options': [],\n",
       " 'gc_stats': [b'bytes_collected', 0],\n",
       " 'cursor_stats': [b'global_idle',\n",
       "  0,\n",
       "  b'global_total',\n",
       "  0,\n",
       "  b'index_capacity',\n",
       "  128,\n",
       "  b'index_total',\n",
       "  0],\n",
       " 'num_docs': 658,\n",
       " 'max_doc_id': 658,\n",
       " 'num_terms': 0,\n",
       " 'num_records': 658,\n",
       " 'inverted_sz_mb': '0',\n",
       " 'total_inverted_index_blocks': 0,\n",
       " 'vector_index_sz_mb': '0.34607315063476562',\n",
       " 'offset_vectors_sz_mb': '0',\n",
       " 'doc_table_size_mb': '0.04633331298828125',\n",
       " 'sortable_values_size_mb': '0',\n",
       " 'key_table_size_mb': '0.018225669860839844',\n",
       " 'records_per_doc_avg': '1',\n",
       " 'bytes_per_record_avg': '0',\n",
       " 'offsets_per_term_avg': '0',\n",
       " 'offset_bits_per_record_avg': 'nan',\n",
       " 'indexing': 0,\n",
       " 'percent_indexed': '1',\n",
       " 'hash_indexing_failures': 0,\n",
       " 'number_of_uses': 1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify Index Construction\n",
    "await redis_conn.ft(INDEX_NAME).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fd490e4-04f7-4d92-926c-8474eea2732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch an Item ID\n",
    "item_ids = [key for key in await redis_conn.keys() if b\"ITEM:\" in key]\n",
    "item_id = item_ids[0]\n",
    "\n",
    "# Fetch a testing input vector\n",
    "test_vector = await redis_conn.hget(item_id.decode(\"utf\"), VECTOR_FIELD_NAME)\n",
    "\n",
    "# Create a Redis VSS Query\n",
    "query = Query(f\"*=>[KNN 10 @{VECTOR_FIELD_NAME} $vec_param AS vector_score]\")\\\n",
    "    .sort_by(\"vector_score\")\\\n",
    "    .return_fields(\"id\", \"vector_score\")\\\n",
    "    .dialect(2)\n",
    "\n",
    "# Search for KNN\n",
    "k_nearest_neighbors = await redis_conn.ft(INDEX_NAME).search(query, query_params={\"vec_param\": test_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39ca01e1-a1f3-4c63-b33b-5874e30f9c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document {'id': 'ITEM:46', 'payload': None, 'vector_score': '0.862593948841'},\n",
       " Document {'id': 'ITEM:278', 'payload': None, 'vector_score': '0.888273656368'},\n",
       " Document {'id': 'ITEM:121', 'payload': None, 'vector_score': '0.894923210144'},\n",
       " Document {'id': 'ITEM:91', 'payload': None, 'vector_score': '0.897271990776'},\n",
       " Document {'id': 'ITEM:267', 'payload': None, 'vector_score': '0.905174136162'},\n",
       " Document {'id': 'ITEM:128', 'payload': None, 'vector_score': '0.908258855343'},\n",
       " Document {'id': 'ITEM:78', 'payload': None, 'vector_score': '0.910417497158'},\n",
       " Document {'id': 'ITEM:130', 'payload': None, 'vector_score': '0.911561369896'},\n",
       " Document {'id': 'ITEM:161', 'payload': None, 'vector_score': '0.912223100662'},\n",
       " Document {'id': 'ITEM:53', 'payload': None, 'vector_score': '0.913191318512'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_nearest_neighbors.docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80678ea1-a7fb-4016-9e6f-c905497f4142",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "In this notebook we created our Redis Feature Store and setup the Redis ANN Index. Next, we will deploy our trained models into [Triton Inference Server (TIS)](https://github.com/triton-inference-server/server).\n",
    "\n",
    "For the next step, move on to the [`02-Deploying-Online-Multi-Stage-Recsys-with-Triton.ipynb`](./02-Deploying-Online-Multi-Stage-Redsys-with-Triton.ipynb) notebook to deploy our saved models as an ensemble to TIS and obtain prediction results for a given request."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059312d7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "merlin": {
   "containers": [
    "nvcr.io/nvidia/merlin/merlin-tensorflow-inference:latest"
   ]
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
